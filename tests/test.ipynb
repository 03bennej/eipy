{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from ens_selection import CES\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "from xgboost import XGBClassifier\n",
    "import sys\n",
    "from utils import dummy_cv\n",
    "\n",
    "path_to_ei = \"/home/jamie/Projects/ei-python\"\n",
    "sys.path.append(path_to_ei)\n",
    "from ei import EnsembleIntegration\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "X, y = make_classification(n_samples=1250, n_features=50, n_redundant=0,\n",
    "n_clusters_per_class=1, weights=[0.95, 0.05], flip_y=0.0, random_state=1)\n",
    "\n",
    "X_1 = X[:, 0:25]\n",
    "X_2 = X[:, 25:]\n",
    "\n",
    "X_1_train, X_1_test, y_1_train, y_1_test = train_test_split(X_1, y, test_size=0.2, random_state=2, shuffle=True, stratify=y)\n",
    "X_2_train, X_2_test, y_2_train, y_2_test = train_test_split(X_2, y, test_size=0.2, random_state=2, shuffle=True, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1188"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y[y==0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y[y==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_1_test[y_1_test==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "                \"X_1\": X_1_train,\n",
    "                \"X_2\": X_2_train\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_predictors = {\n",
    "                'AdaBoost': AdaBoostClassifier(),\n",
    "                'DT': DecisionTreeClassifier(max_depth=3),\n",
    "                'GradientBoosting': GradientBoostingClassifier(n_estimators=100),\n",
    "                'KNN': KNeighborsClassifier(n_neighbors=40),\n",
    "                'LR': LogisticRegression(C=0.5),\n",
    "                'NB': GaussianNB(),\n",
    "                'MLP': MLPClassifier(hidden_layer_sizes=(100, 100, 100), max_iter=200, alpha=1),\n",
    "                'RF': RandomForestClassifier(),\n",
    "                'SVM': SVC(probability=True), \n",
    "                'XGB': XGBClassifier()\n",
    "                    }\n",
    "\n",
    "EI = EnsembleIntegration(base_predictors=base_predictors,\n",
    "                        k_outer=3,\n",
    "                        k_inner=3,\n",
    "                        n_samples=3,\n",
    "                        sampling_strategy=\"undersampling\",\n",
    "                        sampling_aggregation=\"mean\",\n",
    "                        n_jobs=-1,  # set as -1 to use all available CPUs\n",
    "                        random_state=38,\n",
    "                        parallel_backend=\"loky\",\n",
    "                        project_name=\"cell-division\",\n",
    "                        model_building=True,\n",
    "                        # calibration_model=CalibratedClassifierCV(),\n",
    "                        )\n",
    "\n",
    "meta_models = {\n",
    "                'AdaBoost': AdaBoostClassifier(),\n",
    "                'DT': DecisionTreeClassifier(max_depth=3),\n",
    "                'GradientBoosting': GradientBoostingClassifier(n_estimators=100),\n",
    "                'KNN': KNeighborsClassifier(n_neighbors=40),\n",
    "                'LR': LogisticRegression(C=0.5),\n",
    "                'NB': GaussianNB(),\n",
    "                'MLP': MLPClassifier(hidden_layer_sizes=(50), max_iter=200, alpha=1),\n",
    "                'RF': RandomForestClassifier(),\n",
    "                'SVM': SVC(probability=True, C=0.01),\n",
    "                'XGB': XGBClassifier()\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "##############################################################################################\n",
      "######################################## X_1 modality ########################################\n",
      "############################################################################################## \n",
      "\n",
      "\n",
      "Training base predictors and generating data for analysis...\n",
      "Generating meta training data via nested cross validation...\n",
      "Training base predictors on outer training sets...\n",
      "\n",
      "Base predictor training is complete: see \"base_summary\" attribute for a summary of base predictor performance. Meta training data can be found in \"meta_training_data\" and \"meta_test_data\" attributes. Run \"train_meta\" method for analysis of ensemble algorithms.\n",
      "\n",
      "Training base predictors and generating data for final ensemble...\n",
      "Generating meta training data via nested cross validation...\n",
      "Training base predictors on outer training sets...\n",
      "\n",
      "Model building: meta training data for the final model has been generated and can be found in the \"meta_training_data_final\" attribute. Final base predidctors have been saved in the \"final_models\" attribute.\n",
      "\n",
      "\n",
      "##############################################################################################\n",
      "######################################## X_2 modality ########################################\n",
      "############################################################################################## \n",
      "\n",
      "\n",
      "Training base predictors and generating data for analysis...\n",
      "Generating meta training data via nested cross validation...\n",
      "Training base predictors on outer training sets...\n",
      "\n",
      "Base predictor training is complete: see \"base_summary\" attribute for a summary of base predictor performance. Meta training data can be found in \"meta_training_data\" and \"meta_test_data\" attributes. Run \"train_meta\" method for analysis of ensemble algorithms.\n",
      "\n",
      "Training base predictors and generating data for final ensemble...\n",
      "Generating meta training data via nested cross validation...\n",
      "Training base predictors on outer training sets...\n",
      "\n",
      "Model building: meta training data for the final model has been generated and can be found in the \"meta_training_data_final\" attribute. Final base predidctors have been saved in the \"final_models\" attribute.\n",
      "\n",
      "\n",
      "#####################################################################################################\n",
      "######################################## Analysing ensembles ########################################\n",
      "##################################################################################################### \n",
      "\n",
      "\n",
      "Mean...\n",
      "fmax (minority):  0.7045454545454546\n",
      "f (majority):  0.9864016736401673\n",
      "AUC:  0.9519157894736843\n",
      "max MCC:  0.688502203569911\n",
      "\n",
      "CES...\n",
      "fmax (minority):  0.7346938775510204\n",
      "f (majority):  0.9863301787592009\n",
      "AUC:  0.9644631578947368\n",
      "max MCC:  0.7211961168845046\n",
      "\n",
      "S.AdaBoost...\n",
      "fmax (minority):  0.5306122448979592\n",
      "f (majority):  0.9758149316508938\n",
      "AUC:  0.8967578947368421\n",
      "max MCC:  0.5005596152683394\n",
      "\n",
      "S.DT...\n",
      "fmax (minority):  0.4566929133858268\n",
      "f (majority):  0.9631607047517352\n",
      "AUC:  0.7068947368421052\n",
      "max MCC:  0.4328575245820295\n",
      "\n",
      "S.GradientBoosting...\n",
      "fmax (minority):  0.5882352941176471\n",
      "f (majority):  0.9739500265816055\n",
      "AUC:  0.8622842105263158\n",
      "max MCC:  0.5717260677193561\n",
      "\n",
      "S.KNN...\n",
      "fmax (minority):  0.7115384615384615\n",
      "f (majority):  0.9841772151898734\n",
      "AUC:  0.9343578947368422\n",
      "max MCC:  0.6977794368196982\n",
      "\n",
      "S.LR...\n",
      "fmax (minority):  0.7289719626168225\n",
      "f (majority):  0.9846804014791337\n",
      "AUC:  0.9629263157894736\n",
      "max MCC:  0.716164215048093\n",
      "\n",
      "S.NB...\n",
      "fmax (minority):  0.7311827956989247\n",
      "f (majority):  0.9868904037755636\n",
      "AUC:  0.9617894736842105\n",
      "max MCC:  0.5949722719145415\n",
      "\n",
      "S.MLP...\n",
      "fmax (minority):  0.7142857142857142\n",
      "f (majority):  0.9852786540483702\n",
      "AUC:  0.9617263157894737\n",
      "max MCC:  0.7020730419491239\n",
      "\n",
      "S.RF...\n",
      "fmax (minority):  0.6785714285714285\n",
      "f (majority):  0.9809322033898304\n",
      "AUC:  0.9008315789473683\n",
      "max MCC:  0.6640203025480874\n",
      "\n",
      "S.SVM...\n",
      "fmax (minority):  0.7169811320754718\n",
      "f (majority):  0.9841605068637803\n",
      "AUC:  0.8673263157894737\n",
      "max MCC:  0.7024506974060344\n",
      "\n",
      "S.XGB...\n",
      "fmax (minority):  0.6857142857142857\n",
      "f (majority):  0.9825857519788919\n",
      "AUC:  0.8914526315789474\n",
      "max MCC:  0.6693729004945311\n",
      "\n",
      "Analysis complete: performance summary of ensemble algorithms can be found in \"meta_summary\" attribute.\n",
      "\n",
      "Training meta predictors for final ensemble...\n",
      "Model building: final meta models have been saved to \"final_models\" attribute.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ei.EnsembleIntegration at 0x7fc2d84add30>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for name, modality in data.items():\n",
    "    EI.train_base(modality, y_1_train, modality=name)\n",
    "\n",
    "EI.train_meta(meta_models=meta_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(EI.final_models[\"base models\"][\"X_1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5681818181818181\n"
     ]
    }
   ],
   "source": [
    "test_data = {\n",
    "                \"X_1\": X_1_test,\n",
    "                \"X_2\": X_2_test\n",
    "                }\n",
    "\n",
    "ensemble_method = \"S.LR\"\n",
    "\n",
    "y_pred = EI.predict(X_dictionary=test_data, meta_model_key=ensemble_method)\n",
    "\n",
    "threshold = EI.meta_summary[\"thresholds\"][ensemble_method][\"fmax (minority)\"]\n",
    "\n",
    "y_pred_label = y_pred\n",
    "y_pred_label[y_pred_label>threshold] = 1\n",
    "y_pred_label[y_pred_label<=threshold] = 0\n",
    "\n",
    "print(f1_score(y_1_test, y_pred_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = dummy_cv(n_splits=1)\n",
    "for train_ix, test_ix in cv.split(X=X, y=y):\n",
    "    print(X[train_ix, :].shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "11e74c3c36c376ffcb66f65df8248706fe68363becca747991fd07d52526dccb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
